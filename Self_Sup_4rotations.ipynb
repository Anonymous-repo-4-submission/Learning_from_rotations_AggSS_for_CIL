{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teja/anaconda3/envs/slca/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=40):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes, bias=False)\n",
    "\n",
    "        if block == BasicBlock:\n",
    "            self.name = \"resnet\" + str(sum(num_blocks) * 2 + 2)\n",
    "        else:\n",
    "            self.name = \"resnet\" + str(sum(num_blocks) * 3 + 2)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #out = self.linear(out)\n",
    "        out = F.linear(F.normalize(out, p=2, dim=-1), F.normalize(self.linear.weight, p=2, dim=-1))\n",
    "       \n",
    "        return out*16\n",
    "    def embed(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "net = ResNet18()\n",
    "net=net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.optim.lr_scheduler.MultiStepLR as MultiStepLR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=70, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20,30,40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    correct_agg = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = torch.stack([torch.rot90(inputs, k, (2, 3)) for k in range(4)], 1)\n",
    "        inputs = inputs.view(-1, 3, 32, 32)\n",
    "        targets = torch.stack([targets * 4 + k for k in range(4)], 1).view(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        #print(outputs.shape)\n",
    "        #print(c)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        \n",
    "    print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total,correct, total))\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    correct_agg = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs[:, ::4].max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            inputs = torch.stack([torch.rot90(inputs, k, (2, 3)) for k in range(4)], 1)\n",
    "            inputs = inputs.view(-1, 3, 32, 32)\n",
    "            outputs = net(inputs)\n",
    "            AG = 0.\n",
    "            for k in range(4):\n",
    "                AG = AG + outputs[k::4, k::4] / 4.\n",
    "            _, predicted = AG.max(1)\n",
    "            #total += targets.size(0)\n",
    "            correct_agg += predicted.eq(targets).sum().item()\n",
    "            \n",
    "\n",
    "        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% | AggAcc: %.3f%%  (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, 100.*correct_agg/total,correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "390 391 Loss: 2.373 | Acc: 33.019% (66038/200000)\n",
      "99 100 Loss: 6.087 | Acc: 54.530% | AggAcc: 54.020%  (5453/10000)\n",
      "\n",
      "Epoch: 1\n",
      "390 391 Loss: 1.392 | Acc: 58.916% (117833/200000)\n",
      "99 100 Loss: 7.834 | Acc: 68.980% | AggAcc: 72.440%  (6898/10000)\n",
      "\n",
      "Epoch: 2\n",
      "390 391 Loss: 1.032 | Acc: 69.180% (138360/200000)\n",
      "99 100 Loss: 7.899 | Acc: 72.670% | AggAcc: 79.040%  (7267/10000)\n",
      "\n",
      "Epoch: 3\n",
      "390 391 Loss: 0.851 | Acc: 74.410% (148820/200000)\n",
      "99 100 Loss: 8.809 | Acc: 80.590% | AggAcc: 81.090%  (8059/10000)\n",
      "\n",
      "Epoch: 4\n",
      "390 391 Loss: 0.756 | Acc: 77.115% (154230/200000)\n",
      "99 100 Loss: 8.450 | Acc: 82.690% | AggAcc: 84.590%  (8269/10000)\n",
      "\n",
      "Epoch: 5\n",
      "390 391 Loss: 0.687 | Acc: 79.088% (158177/200000)\n",
      "99 100 Loss: 9.180 | Acc: 84.910% | AggAcc: 86.420%  (8491/10000)\n",
      "\n",
      "Epoch: 6\n",
      "390 391 Loss: 0.644 | Acc: 80.322% (160643/200000)\n",
      "99 100 Loss: 8.693 | Acc: 83.190% | AggAcc: 86.470%  (8319/10000)\n",
      "\n",
      "Epoch: 7\n",
      "390 391 Loss: 0.623 | Acc: 81.086% (162172/200000)\n",
      "99 100 Loss: 9.040 | Acc: 82.970% | AggAcc: 84.960%  (8297/10000)\n",
      "\n",
      "Epoch: 8\n",
      "390 391 Loss: 0.593 | Acc: 81.871% (163742/200000)\n",
      "99 100 Loss: 8.807 | Acc: 81.840% | AggAcc: 85.560%  (8184/10000)\n",
      "\n",
      "Epoch: 9\n",
      "390 391 Loss: 0.565 | Acc: 82.683% (165365/200000)\n",
      "99 100 Loss: 9.444 | Acc: 86.850% | AggAcc: 88.780%  (8685/10000)\n",
      "\n",
      "Epoch: 10\n",
      "390 391 Loss: 0.558 | Acc: 82.891% (165783/200000)\n",
      "99 100 Loss: 9.561 | Acc: 85.600% | AggAcc: 88.980%  (8560/10000)\n",
      "\n",
      "Epoch: 11\n",
      "390 391 Loss: 0.539 | Acc: 83.512% (167024/200000)\n",
      "99 100 Loss: 9.244 | Acc: 84.700% | AggAcc: 86.950%  (8470/10000)\n",
      "\n",
      "Epoch: 12\n",
      "390 391 Loss: 0.525 | Acc: 83.868% (167735/200000)\n",
      "99 100 Loss: 9.361 | Acc: 80.500% | AggAcc: 85.350%  (8050/10000)\n",
      "\n",
      "Epoch: 13\n",
      "390 391 Loss: 0.513 | Acc: 84.109% (168218/200000)\n",
      "99 100 Loss: 9.150 | Acc: 85.510% | AggAcc: 88.380%  (8551/10000)\n",
      "\n",
      "Epoch: 14\n",
      "390 391 Loss: 0.506 | Acc: 84.401% (168803/200000)\n",
      "99 100 Loss: 9.477 | Acc: 83.120% | AggAcc: 85.870%  (8312/10000)\n",
      "\n",
      "Epoch: 15\n",
      "390 391 Loss: 0.500 | Acc: 84.641% (169282/200000)\n",
      "99 100 Loss: 9.928 | Acc: 86.200% | AggAcc: 87.680%  (8620/10000)\n",
      "\n",
      "Epoch: 16\n",
      "390 391 Loss: 0.494 | Acc: 84.825% (169649/200000)\n",
      "99 100 Loss: 9.057 | Acc: 84.880% | AggAcc: 87.000%  (8488/10000)\n",
      "\n",
      "Epoch: 17\n",
      "390 391 Loss: 0.485 | Acc: 85.026% (170052/200000)\n",
      "99 100 Loss: 9.817 | Acc: 84.550% | AggAcc: 86.750%  (8455/10000)\n",
      "\n",
      "Epoch: 18\n",
      "390 391 Loss: 0.476 | Acc: 85.253% (170506/200000)\n",
      "99 100 Loss: 9.315 | Acc: 83.770% | AggAcc: 86.970%  (8377/10000)\n",
      "\n",
      "Epoch: 19\n",
      "390 391 Loss: 0.472 | Acc: 85.396% (170792/200000)\n",
      "99 100 Loss: 10.076 | Acc: 81.100% | AggAcc: 81.430%  (8110/10000)\n",
      "\n",
      "Epoch: 20\n",
      "390 391 Loss: 0.272 | Acc: 91.556% (183113/200000)\n",
      "99 100 Loss: 10.804 | Acc: 93.220% | AggAcc: 94.300%  (9322/10000)\n",
      "\n",
      "Epoch: 21\n",
      "390 391 Loss: 0.210 | Acc: 93.326% (186652/200000)\n",
      "99 100 Loss: 10.842 | Acc: 93.660% | AggAcc: 94.670%  (9366/10000)\n",
      "\n",
      "Epoch: 22\n",
      "390 391 Loss: 0.189 | Acc: 94.019% (188039/200000)\n",
      "99 100 Loss: 10.924 | Acc: 93.770% | AggAcc: 94.870%  (9377/10000)\n",
      "\n",
      "Epoch: 23\n",
      "390 391 Loss: 0.171 | Acc: 94.549% (189099/200000)\n",
      "99 100 Loss: 11.023 | Acc: 93.970% | AggAcc: 94.920%  (9397/10000)\n",
      "\n",
      "Epoch: 24\n",
      "390 391 Loss: 0.154 | Acc: 95.051% (190102/200000)\n",
      "99 100 Loss: 11.134 | Acc: 93.920% | AggAcc: 94.920%  (9392/10000)\n",
      "\n",
      "Epoch: 25\n",
      "390 391 Loss: 0.144 | Acc: 95.388% (190776/200000)\n",
      "99 100 Loss: 11.024 | Acc: 94.030% | AggAcc: 94.990%  (9403/10000)\n",
      "\n",
      "Epoch: 26\n",
      "390 391 Loss: 0.131 | Acc: 95.769% (191539/200000)\n",
      "99 100 Loss: 11.161 | Acc: 94.030% | AggAcc: 95.240%  (9403/10000)\n",
      "\n",
      "Epoch: 27\n",
      "390 391 Loss: 0.122 | Acc: 96.079% (192158/200000)\n",
      "99 100 Loss: 11.098 | Acc: 93.910% | AggAcc: 95.380%  (9391/10000)\n",
      "\n",
      "Epoch: 28\n",
      "390 391 Loss: 0.117 | Acc: 96.243% (192487/200000)\n",
      "99 100 Loss: 11.179 | Acc: 94.260% | AggAcc: 95.270%  (9426/10000)\n",
      "\n",
      "Epoch: 29\n",
      "390 391 Loss: 0.107 | Acc: 96.578% (193156/200000)\n",
      "99 100 Loss: 11.129 | Acc: 94.280% | AggAcc: 95.320%  (9428/10000)\n",
      "\n",
      "Epoch: 30\n",
      "390 391 Loss: 0.084 | Acc: 97.389% (194779/200000)\n",
      "99 100 Loss: 11.235 | Acc: 94.610% | AggAcc: 95.700%  (9461/10000)\n",
      "\n",
      "Epoch: 31\n",
      "390 391 Loss: 0.074 | Acc: 97.707% (195413/200000)\n",
      "99 100 Loss: 11.262 | Acc: 94.710% | AggAcc: 95.690%  (9471/10000)\n",
      "\n",
      "Epoch: 32\n",
      "390 391 Loss: 0.072 | Acc: 97.808% (195616/200000)\n",
      "99 100 Loss: 11.262 | Acc: 94.720% | AggAcc: 95.860%  (9472/10000)\n",
      "\n",
      "Epoch: 33\n",
      "390 391 Loss: 0.069 | Acc: 97.874% (195747/200000)\n",
      "99 100 Loss: 11.267 | Acc: 94.680% | AggAcc: 95.730%  (9468/10000)\n",
      "\n",
      "Epoch: 34\n",
      "390 391 Loss: 0.068 | Acc: 97.915% (195829/200000)\n",
      "99 100 Loss: 11.283 | Acc: 94.800% | AggAcc: 95.740%  (9480/10000)\n",
      "\n",
      "Epoch: 35\n",
      "390 391 Loss: 0.065 | Acc: 98.024% (196048/200000)\n",
      "99 100 Loss: 11.295 | Acc: 94.830% | AggAcc: 95.710%  (9483/10000)\n",
      "\n",
      "Epoch: 36\n",
      "390 391 Loss: 0.064 | Acc: 98.055% (196110/200000)\n",
      "99 100 Loss: 11.279 | Acc: 94.740% | AggAcc: 95.750%  (9474/10000)\n",
      "\n",
      "Epoch: 37\n",
      "390 391 Loss: 0.063 | Acc: 98.091% (196182/200000)\n",
      "99 100 Loss: 11.259 | Acc: 94.700% | AggAcc: 95.760%  (9470/10000)\n",
      "\n",
      "Epoch: 38\n",
      "390 391 Loss: 0.060 | Acc: 98.189% (196377/200000)\n",
      "99 100 Loss: 11.299 | Acc: 94.770% | AggAcc: 95.800%  (9477/10000)\n",
      "\n",
      "Epoch: 39\n",
      "390 391 Loss: 0.058 | Acc: 98.284% (196567/200000)\n",
      "99 100 Loss: 11.304 | Acc: 94.780% | AggAcc: 95.890%  (9478/10000)\n",
      "\n",
      "Epoch: 40\n",
      "390 391 Loss: 0.055 | Acc: 98.355% (196710/200000)\n",
      "99 100 Loss: 11.286 | Acc: 94.690% | AggAcc: 95.820%  (9469/10000)\n",
      "\n",
      "Epoch: 41\n",
      "390 391 Loss: 0.056 | Acc: 98.326% (196652/200000)\n",
      "99 100 Loss: 11.283 | Acc: 94.670% | AggAcc: 95.800%  (9467/10000)\n",
      "\n",
      "Epoch: 42\n",
      "390 391 Loss: 0.056 | Acc: 98.305% (196609/200000)\n",
      "99 100 Loss: 11.305 | Acc: 94.750% | AggAcc: 95.780%  (9475/10000)\n",
      "\n",
      "Epoch: 43\n",
      "390 391 Loss: 0.056 | Acc: 98.358% (196715/200000)\n",
      "99 100 Loss: 11.325 | Acc: 94.850% | AggAcc: 95.790%  (9485/10000)\n",
      "\n",
      "Epoch: 44\n",
      "390 391 Loss: 0.055 | Acc: 98.337% (196674/200000)\n",
      "99 100 Loss: 11.296 | Acc: 94.700% | AggAcc: 95.880%  (9470/10000)\n",
      "\n",
      "Epoch: 45\n",
      "390 391 Loss: 0.054 | Acc: 98.393% (196786/200000)\n",
      "99 100 Loss: 11.315 | Acc: 94.720% | AggAcc: 95.800%  (9472/10000)\n",
      "\n",
      "Epoch: 46\n",
      "390 391 Loss: 0.055 | Acc: 98.339% (196678/200000)\n",
      "99 100 Loss: 11.268 | Acc: 94.770% | AggAcc: 95.840%  (9477/10000)\n",
      "\n",
      "Epoch: 47\n",
      "390 391 Loss: 0.055 | Acc: 98.330% (196660/200000)\n",
      "99 100 Loss: 11.312 | Acc: 94.730% | AggAcc: 95.800%  (9473/10000)\n",
      "\n",
      "Epoch: 48\n",
      "390 391 Loss: 0.055 | Acc: 98.336% (196672/200000)\n",
      "99 100 Loss: 11.298 | Acc: 94.710% | AggAcc: 95.790%  (9471/10000)\n",
      "\n",
      "Epoch: 49\n",
      "390 391 Loss: 0.054 | Acc: 98.390% (196780/200000)\n",
      "99 100 Loss: 11.327 | Acc: 94.800% | AggAcc: 95.800%  (9480/10000)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+50):\n",
    "    # In PyTorch 1.1.0 and later,\n",
    "    # you should call them in the opposite order:\n",
    "    # `optimizer.step()` before `lr_scheduler.step()`\n",
    "    train(epoch)\n",
    "    scheduler.step()\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
