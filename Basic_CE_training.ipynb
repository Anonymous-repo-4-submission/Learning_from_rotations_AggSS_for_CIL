{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teja/anaconda3/envs/slca/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes, bias=False)\n",
    "\n",
    "        if block == BasicBlock:\n",
    "            self.name = \"resnet\" + str(sum(num_blocks) * 2 + 2)\n",
    "        else:\n",
    "            self.name = \"resnet\" + str(sum(num_blocks) * 3 + 2)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #out = self.linear(out)\n",
    "        out = F.linear(F.normalize(out, p=2, dim=-1), F.normalize(self.linear.weight, p=2, dim=-1))\n",
    "       \n",
    "        return out*16\n",
    "    def embed(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "net = ResNet18()\n",
    "net=net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.optim.lr_scheduler.MultiStepLR as MultiStepLR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=70, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20,30,40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    correct_agg = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # inputs = torch.stack([torch.rot90(inputs, k, (2, 3)) for k in range(4)], 1)\n",
    "        # inputs = inputs.view(-1, 3, 32, 32)\n",
    "        # targets = torch.stack([targets * 4 + k for k in range(4)], 1).view(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        #print(outputs.shape)\n",
    "        #print(c)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        \n",
    "    print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total,correct, total))\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    correct_agg = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "\n",
    "        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%%'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "390 391 Loss: 1.894 | Acc: 34.074% (17037/50000)\n",
      "99 100 Loss: 1.621 | Acc: 41.230%\n",
      "\n",
      "Epoch: 1\n",
      "390 391 Loss: 1.360 | Acc: 50.478% (25239/50000)\n",
      "99 100 Loss: 1.224 | Acc: 55.200%\n",
      "\n",
      "Epoch: 2\n",
      "390 391 Loss: 1.060 | Acc: 62.234% (31117/50000)\n",
      "99 100 Loss: 1.132 | Acc: 60.600%\n",
      "\n",
      "Epoch: 3\n",
      "390 391 Loss: 0.880 | Acc: 69.210% (34605/50000)\n",
      "99 100 Loss: 1.002 | Acc: 65.250%\n",
      "\n",
      "Epoch: 4\n",
      "390 391 Loss: 0.759 | Acc: 73.544% (36772/50000)\n",
      "99 100 Loss: 0.906 | Acc: 68.740%\n",
      "\n",
      "Epoch: 5\n",
      "390 391 Loss: 0.656 | Acc: 77.212% (38606/50000)\n",
      "99 100 Loss: 0.750 | Acc: 74.360%\n",
      "\n",
      "Epoch: 6\n",
      "390 391 Loss: 0.588 | Acc: 79.718% (39859/50000)\n",
      "99 100 Loss: 0.685 | Acc: 76.270%\n",
      "\n",
      "Epoch: 7\n",
      "390 391 Loss: 0.547 | Acc: 81.250% (40625/50000)\n",
      "99 100 Loss: 0.947 | Acc: 70.340%\n",
      "\n",
      "Epoch: 8\n",
      "390 391 Loss: 0.514 | Acc: 82.250% (41125/50000)\n",
      "99 100 Loss: 1.096 | Acc: 65.210%\n",
      "\n",
      "Epoch: 9\n",
      "390 391 Loss: 0.488 | Acc: 83.270% (41635/50000)\n",
      "99 100 Loss: 0.988 | Acc: 69.460%\n",
      "\n",
      "Epoch: 10\n",
      "390 391 Loss: 0.470 | Acc: 84.062% (42031/50000)\n",
      "99 100 Loss: 0.599 | Acc: 79.810%\n",
      "\n",
      "Epoch: 11\n",
      "390 391 Loss: 0.461 | Acc: 84.200% (42100/50000)\n",
      "99 100 Loss: 0.829 | Acc: 73.800%\n",
      "\n",
      "Epoch: 12\n",
      "390 391 Loss: 0.435 | Acc: 85.070% (42535/50000)\n",
      "99 100 Loss: 0.558 | Acc: 81.120%\n",
      "\n",
      "Epoch: 13\n",
      "390 391 Loss: 0.428 | Acc: 85.086% (42543/50000)\n",
      "99 100 Loss: 0.660 | Acc: 78.770%\n",
      "\n",
      "Epoch: 14\n",
      "390 391 Loss: 0.421 | Acc: 85.418% (42709/50000)\n",
      "99 100 Loss: 0.559 | Acc: 80.580%\n",
      "\n",
      "Epoch: 15\n",
      "390 391 Loss: 0.404 | Acc: 86.170% (43085/50000)\n",
      "99 100 Loss: 0.697 | Acc: 76.790%\n",
      "\n",
      "Epoch: 16\n",
      "390 391 Loss: 0.397 | Acc: 86.488% (43244/50000)\n",
      "99 100 Loss: 0.497 | Acc: 83.310%\n",
      "\n",
      "Epoch: 17\n",
      "390 391 Loss: 0.393 | Acc: 86.608% (43304/50000)\n",
      "99 100 Loss: 0.609 | Acc: 80.530%\n",
      "\n",
      "Epoch: 18\n",
      "390 391 Loss: 0.388 | Acc: 86.798% (43399/50000)\n",
      "99 100 Loss: 0.734 | Acc: 76.300%\n",
      "\n",
      "Epoch: 19\n",
      "390 391 Loss: 0.393 | Acc: 86.440% (43220/50000)\n",
      "99 100 Loss: 0.532 | Acc: 82.470%\n",
      "\n",
      "Epoch: 20\n",
      "390 391 Loss: 0.217 | Acc: 92.584% (46292/50000)\n",
      "99 100 Loss: 0.262 | Acc: 91.120%\n",
      "\n",
      "Epoch: 21\n",
      "390 391 Loss: 0.166 | Acc: 94.420% (47210/50000)\n",
      "99 100 Loss: 0.245 | Acc: 91.960%\n",
      "\n",
      "Epoch: 22\n",
      "390 391 Loss: 0.148 | Acc: 94.998% (47499/50000)\n",
      "99 100 Loss: 0.239 | Acc: 92.100%\n",
      "\n",
      "Epoch: 23\n",
      "390 391 Loss: 0.135 | Acc: 95.398% (47699/50000)\n",
      "99 100 Loss: 0.239 | Acc: 92.070%\n",
      "\n",
      "Epoch: 24\n",
      "390 391 Loss: 0.120 | Acc: 95.958% (47979/50000)\n",
      "99 100 Loss: 0.240 | Acc: 92.300%\n",
      "\n",
      "Epoch: 25\n",
      "390 391 Loss: 0.109 | Acc: 96.270% (48135/50000)\n",
      "99 100 Loss: 0.233 | Acc: 92.400%\n",
      "\n",
      "Epoch: 26\n",
      "390 391 Loss: 0.102 | Acc: 96.518% (48259/50000)\n",
      "99 100 Loss: 0.240 | Acc: 92.640%\n",
      "\n",
      "Epoch: 27\n",
      "390 391 Loss: 0.090 | Acc: 96.864% (48432/50000)\n",
      "99 100 Loss: 0.248 | Acc: 92.470%\n",
      "\n",
      "Epoch: 28\n",
      "390 391 Loss: 0.085 | Acc: 97.108% (48554/50000)\n",
      "99 100 Loss: 0.244 | Acc: 92.560%\n",
      "\n",
      "Epoch: 29\n",
      "390 391 Loss: 0.080 | Acc: 97.280% (48640/50000)\n",
      "99 100 Loss: 0.255 | Acc: 92.350%\n",
      "\n",
      "Epoch: 30\n",
      "390 391 Loss: 0.059 | Acc: 98.082% (49041/50000)\n",
      "99 100 Loss: 0.230 | Acc: 93.040%\n",
      "\n",
      "Epoch: 31\n",
      "390 391 Loss: 0.052 | Acc: 98.356% (49178/50000)\n",
      "99 100 Loss: 0.230 | Acc: 93.160%\n",
      "\n",
      "Epoch: 32\n",
      "390 391 Loss: 0.047 | Acc: 98.536% (49268/50000)\n",
      "99 100 Loss: 0.228 | Acc: 93.270%\n",
      "\n",
      "Epoch: 33\n",
      "390 391 Loss: 0.045 | Acc: 98.580% (49290/50000)\n",
      "99 100 Loss: 0.229 | Acc: 93.250%\n",
      "\n",
      "Epoch: 34\n",
      "390 391 Loss: 0.041 | Acc: 98.688% (49344/50000)\n",
      "99 100 Loss: 0.233 | Acc: 93.160%\n",
      "\n",
      "Epoch: 35\n",
      "390 391 Loss: 0.041 | Acc: 98.740% (49370/50000)\n",
      "99 100 Loss: 0.232 | Acc: 93.210%\n",
      "\n",
      "Epoch: 36\n",
      "390 391 Loss: 0.040 | Acc: 98.768% (49384/50000)\n",
      "99 100 Loss: 0.235 | Acc: 93.180%\n",
      "\n",
      "Epoch: 37\n",
      "390 391 Loss: 0.037 | Acc: 98.840% (49420/50000)\n",
      "99 100 Loss: 0.236 | Acc: 93.220%\n",
      "\n",
      "Epoch: 38\n",
      "390 391 Loss: 0.035 | Acc: 98.978% (49489/50000)\n",
      "99 100 Loss: 0.236 | Acc: 93.410%\n",
      "\n",
      "Epoch: 39\n",
      "390 391 Loss: 0.034 | Acc: 98.974% (49487/50000)\n",
      "99 100 Loss: 0.235 | Acc: 93.330%\n",
      "\n",
      "Epoch: 40\n",
      "390 391 Loss: 0.032 | Acc: 99.046% (49523/50000)\n",
      "99 100 Loss: 0.234 | Acc: 93.370%\n",
      "\n",
      "Epoch: 41\n",
      "390 391 Loss: 0.032 | Acc: 99.062% (49531/50000)\n",
      "99 100 Loss: 0.237 | Acc: 93.270%\n",
      "\n",
      "Epoch: 42\n",
      "390 391 Loss: 0.032 | Acc: 99.048% (49524/50000)\n",
      "99 100 Loss: 0.235 | Acc: 93.370%\n",
      "\n",
      "Epoch: 43\n",
      "390 391 Loss: 0.031 | Acc: 99.082% (49541/50000)\n",
      "99 100 Loss: 0.235 | Acc: 93.270%\n",
      "\n",
      "Epoch: 44\n",
      "390 391 Loss: 0.032 | Acc: 99.076% (49538/50000)\n",
      "99 100 Loss: 0.236 | Acc: 93.340%\n",
      "\n",
      "Epoch: 45\n",
      "390 391 Loss: 0.031 | Acc: 99.080% (49540/50000)\n",
      "99 100 Loss: 0.235 | Acc: 93.250%\n",
      "\n",
      "Epoch: 46\n",
      "390 391 Loss: 0.031 | Acc: 99.054% (49527/50000)\n",
      "99 100 Loss: 0.235 | Acc: 93.320%\n",
      "\n",
      "Epoch: 47\n",
      "390 391 Loss: 0.032 | Acc: 99.016% (49508/50000)\n",
      "99 100 Loss: 0.236 | Acc: 93.410%\n",
      "\n",
      "Epoch: 48\n",
      "390 391 Loss: 0.031 | Acc: 99.102% (49551/50000)\n",
      "99 100 Loss: 0.236 | Acc: 93.320%\n",
      "\n",
      "Epoch: 49\n",
      "390 391 Loss: 0.030 | Acc: 99.146% (49573/50000)\n",
      "99 100 Loss: 0.237 | Acc: 93.370%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+50):\n",
    "    # In PyTorch 1.1.0 and later,\n",
    "    # you should call them in the opposite order:\n",
    "    # `optimizer.step()` before `lr_scheduler.step()`\n",
    "    train(epoch)\n",
    "    scheduler.step()\n",
    "    test(epoch)\n",
    "    \n",
    "print(\"Training done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('slca')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12374763ca5268d1a344e2089642727081032c75eee243a864eb80e7d4e083b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
